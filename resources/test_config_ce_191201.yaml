# path to the checkpoint file containing the model
model_path: checkpoint/191201_Final/best_checkpoint.pytorch
# Should the patches be stored in memory or written directly to H5 during prediction.
# Set to True if you have enough RAM cause it's way faster
store_predictions_in_memory: True
# model configuration
model:
  # model class
  name: UNet3D
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  out_channels: 4
  # determines the order of operators in a single layer (crg - Conv3d+ReLU+GroupNorm)
  layer_order: crg
  # feature maps scale factor
  f_maps: 64
  # basic module
  basic_module: DoubleConv
  # number of groups in the groupnorm
  num_groups: 8
  # apply element-wise nn.Sigmoid after the final 1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: false
# specify the test datasets
datasets:
  # patch size given to the network (adapt to fit in your GPU mem)
#  patch: [64, 128, 128]
  patch: [64, 96, 96]
  # stride between patches (make sure the the patches overlap in order to get smoother prediction maps)
#  stride: [32, 100, 100]
  stride: [8, 24, 24]
  # path to the raw data within the H5
  raw_internal_path: raw
  # how many subprocesses to use for data loading
  num_workers: 8
  # paths to the datasets
  test_path:
    - 'CS470/h5_data_1130/test'
  output_path:
    - 'CS470/result/191201_final'
  transformer:
    test:
      raw:
        - name: Normalize
        - name: ToTensor
          expand_dims: true


  eval_metric: MeanIoU
  threshold: 0.7
